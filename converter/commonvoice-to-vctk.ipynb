{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from typing import List\n",
    "import json \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the validated tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cm/lb23lq6s6f319w__2lgw1zfm0000gn/T/ipykernel_83408/1241631071.py:1: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  validated_data = pd.read_csv('../data/raw/cv-corpus-20.0-2024-12-06/th/validated.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "validated_data = pd.read_csv('../data/raw/cv-corpus-20.0-2024-12-06/th/validated.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define word replacement function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(dataframe: pd.DataFrame, column_name: str, replacing_pairs: List[List[str]]) -> pd.DataFrame:\n",
    "    for old_word, new_word in replacing_pairs:\n",
    "        dataframe[column_name] = dataframe[column_name].apply(lambda x: x.replace(old_word, new_word))\n",
    "    return dataframe\n",
    "\n",
    "replacing_word = [\n",
    "    ['เพฃร', 'เพชร'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter and group client_id that have over 100 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cm/lb23lq6s6f319w__2lgw1zfm0000gn/T/ipykernel_83408/1479821191.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[column_name] = dataframe[column_name].apply(lambda x: x.replace(old_word, new_word))\n"
     ]
    }
   ],
   "source": [
    "filtered_data = validated_data[\n",
    "    validated_data['client_id'].map(\n",
    "        validated_data['client_id'].value_counts() >= 100\n",
    "    )\n",
    "]\n",
    "filtered_data = replace_words(filtered_data, 'sentence', replacing_word)\n",
    "grouped = filtered_data.groupby('client_id').agg(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define new id instead of client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mapper = {id_: f'cv{str(i+1).zfill(3)}' for i, id_ in enumerate(filtered_data['client_id'].unique())}\n",
    "\n",
    "grouped_data = {\n",
    "    id_mapper[client_id]: list(zip(sentences, paths))\n",
    "    for (client_id, (sentences, paths)) in grouped[['sentence', 'path']].iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving files to the new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 134/134 [00:55<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restructuring complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "DEST_DIR = \"../data/converted/commonvoice-to-vctk\"\n",
    "DEST_TEXT_PATH = os.path.join(DEST_DIR, \"txt\")\n",
    "DEST_AUDIO_PATH = os.path.join(DEST_DIR, \"wav48\")\n",
    "SRC_AUDIO_PATH = \"../data/raw/cv-corpus-20.0-2024-12-06/th/clips\"\n",
    "\n",
    "# Clean and create directories\n",
    "if os.path.exists(DEST_DIR):\n",
    "   print(\"Clearing destination folder\")\n",
    "   shutil.rmtree(DEST_DIR)\n",
    "os.makedirs(DEST_TEXT_PATH, exist_ok=True)\n",
    "os.makedirs(DEST_AUDIO_PATH, exist_ok=True)\n",
    "\n",
    "all_chars = set()\n",
    "\n",
    "# Process files with progress bar\n",
    "for client_id, data in tqdm(grouped_data.items(), desc=\"Processing\"):\n",
    "   client_text_dir = os.path.join(DEST_TEXT_PATH, client_id)\n",
    "   client_mp3_dir = os.path.join(DEST_AUDIO_PATH, client_id)\n",
    "   os.makedirs(client_text_dir, exist_ok=True)\n",
    "   os.makedirs(client_mp3_dir, exist_ok=True)\n",
    "\n",
    "   for i, d in enumerate(data):\n",
    "       # Write text file\n",
    "       text_path = os.path.join(client_text_dir, f\"{client_id}_{(i + 1):03d}.txt\")\n",
    "       with open(text_path, 'w') as f:\n",
    "           f.write(d[0])\n",
    "           all_chars.update(d[0])\n",
    "\n",
    "       # Copy audio file  \n",
    "       shutil.copyfile(\n",
    "           os.path.join(SRC_AUDIO_PATH, d[1]),\n",
    "           os.path.join(client_mp3_dir, f\"{client_id}_{i:03d}.mp3\")\n",
    "       )\n",
    "\n",
    "print(\"Restructuring complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEST_DIR = Path(DEST_DIR)\n",
    "\n",
    "json_files = {\n",
    "   'grouped_data.json': [\n",
    "       {\"client_id\": cid, \"data\": [{\"path\": d[1], \"sentence\": d[0]} for d in data]}\n",
    "       for cid, data in grouped_data.items()\n",
    "   ],\n",
    "   'language_ids.json': {'th': 0},\n",
    "   'speakers_ids.json': {cid: i for i, cid in enumerate(grouped_data)},\n",
    "   'id_mapper.json': id_mapper\n",
    "}\n",
    "\n",
    "# Write JSON files\n",
    "for filename, data in json_files.items():\n",
    "   with open(DEST_DIR / filename, 'w') as f:\n",
    "       json.dump(data, f, indent=2)\n",
    "\n",
    "# Write character files\n",
    "sorted_chars = sorted(all_chars)\n",
    "with open(DEST_DIR / 'all_chars_unicode.txt', 'w') as f:\n",
    "   f.write(''.join(c.encode('unicode_escape').decode('ascii') for c in sorted_chars))\n",
    "   \n",
    "with open(DEST_DIR / 'all_chars.txt', 'w') as f:\n",
    "   f.write(''.join(sorted_chars))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
