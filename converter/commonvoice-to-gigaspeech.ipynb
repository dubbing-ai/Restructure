{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import concurrent.futures\n",
    "from typing import List, Tuple, Dict\n",
    "import multiprocessing\n",
    "\n",
    "import soundfile as sf\n",
    "import io\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from datasets import Dataset, DatasetDict, Audio\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.audio_util import convert_mp3_to_wav, resample_audios, trim_silence_with_vad\n",
    "from utils.file_util import recursive_copy\n",
    "from utils.text_util import clean_text_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huggingface login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the validated tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_348002/1241631071.py:1: DtypeWarning: Columns (9,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  validated_data = pd.read_csv('../data/raw/cv-corpus-20.0-2024-12-06/th/validated.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "validated_data = pd.read_csv('../data/raw/cv-corpus-20.0-2024-12-06/th/validated.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define word replacement function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {\n",
    "    \"Facebook\": \"เฟซบุ๊ก\",\n",
    "    \"softmax\": \"ซอฟต์แม็กซ์\",\n",
    "    \"Astroturf\": \"แอสโตรเทิร์ฟ\",\n",
    "    \"Burke\": \"เบิร์ก\",\n",
    "    \"whilst\": \"ไวล์สท์\",\n",
    "    \"Kenny\": \"เคนนี\",\n",
    "    \"Flickr\": \"ฟลิกเกอร์\",\n",
    "    \"Asperger\": \"แอสเพอร์เกอร์\",\n",
    "    \"Johanna\": \"โจแอนนา\",\n",
    "    \"C\" : \"ซี\",\n",
    "    \"section\": \"เซคชัน\",\n",
    "    \"Mr Lincoln\": \"มิสเตอร์ ลินคอล์น\",\n",
    "    \"Brexiteers\": \"เบร็กซิทเทียร์ส\",\n",
    "    \"Brexit\": \"เบร็กซิท\"\n",
    "}\n",
    "\n",
    "def preprocess_words(dataframe: pd.DataFrame, column_name: str, replacing_pairs: List[List[str]]) -> pd.DataFrame:\n",
    "    for old_word, new_word in replacing_pairs:\n",
    "        dataframe[column_name] = dataframe[column_name].apply(lambda x: x.replace(old_word, new_word))\n",
    "    dataframe[column_name] = dataframe[column_name].apply(clean_text_cv, replace_dict=replace_dict)\n",
    "    return dataframe\n",
    "\n",
    "replacing_word = [\n",
    "    ['เพฃร', 'เพชร'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter and group client_id that have over 100 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_348002/1772708983.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[column_name] = dataframe[column_name].apply(lambda x: x.replace(old_word, new_word))\n",
      "/tmp/ipykernel_348002/1772708983.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[column_name] = dataframe[column_name].apply(clean_text_cv)\n"
     ]
    }
   ],
   "source": [
    "filtered_data = validated_data[\n",
    "    validated_data['client_id'].map(\n",
    "        validated_data['client_id'].value_counts() >= 100\n",
    "    )\n",
    "]\n",
    "filtered_data = preprocess_words(filtered_data, 'sentence', replacing_word)\n",
    "grouped = filtered_data.groupby('client_id').agg(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define new id instead of client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mapper = {id_: f'cv{str(i+1).zfill(3)}' for i, id_ in enumerate(filtered_data['client_id'].unique())}\n",
    "\n",
    "grouped_data = {\n",
    "    id_mapper[client_id]: list(zip(sentences, paths))\n",
    "    for (client_id, (sentences, paths)) in grouped[['sentence', 'path']].iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving files to the new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel processing with 6 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clients: 100%|██████████| 134/134 [22:54<00:00, 10.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversion Summary:\n",
      "Total files processed successfully: 92956\n",
      "Total files failed: 0\n",
      "Total unique characters: 98\n",
      "Restructuring and conversion complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "DEST_DIR = \"../data/converted/commonvoice-to-gigaspeech\"\n",
    "DEST_TEXT_PATH = os.path.join(DEST_DIR, \"txt\")\n",
    "DEST_AUDIO_PATH = os.path.join(DEST_DIR, \"wav32\")\n",
    "SRC_AUDIO_PATH = \"../data/raw/cv-corpus-20.0-2024-12-06/th/clips\"\n",
    "\n",
    "# Number of worker threads (adjust based on your CPU)\n",
    "NUM_WORKERS = multiprocessing.cpu_count()\n",
    "\n",
    "def process_client_data(client_data: Tuple[str, List]) -> Dict:\n",
    "    \"\"\"\n",
    "    Process all data for a single client\n",
    "    \n",
    "    Args:\n",
    "        client_data: Tuple of (client_id, data)\n",
    "    \n",
    "    Returns:\n",
    "        Dict with processing results\n",
    "    \"\"\"\n",
    "    client_id, data = client_data\n",
    "    results = {\n",
    "        'client_id': client_id,\n",
    "        'processed': 0,\n",
    "        'failed': 0,\n",
    "        'chars': set()\n",
    "    }\n",
    "    \n",
    "    # Create client directories\n",
    "    client_text_dir = os.path.join(DEST_TEXT_PATH, client_id)\n",
    "    client_audio_dir = os.path.join(DEST_AUDIO_PATH, client_id)\n",
    "    os.makedirs(client_text_dir, exist_ok=True)\n",
    "    os.makedirs(client_audio_dir, exist_ok=True)\n",
    "    \n",
    "    for i, d in enumerate(data):\n",
    "        # Write text file\n",
    "        text_path = os.path.join(client_text_dir, f\"{client_id}_{(i + 1):03d}.txt\")\n",
    "        with open(text_path, 'w') as f:\n",
    "            f.write(d[0])\n",
    "            results['chars'].update(d[0])\n",
    "        \n",
    "        # Convert audio file\n",
    "        src_audio_path = os.path.join(SRC_AUDIO_PATH, d[1])\n",
    "        dst_audio_path = os.path.join(\n",
    "            client_audio_dir,\n",
    "            f\"{client_id}_{(i + 1):03d}_mic1.wav\"\n",
    "        )\n",
    "        \n",
    "        if convert_mp3_to_wav(src_audio_path, dst_audio_path):\n",
    "            results['processed'] += 1\n",
    "        else:\n",
    "            results['failed'] += 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Clean and create directories\n",
    "if os.path.exists(DEST_DIR):\n",
    "    print(\"Clearing destination folder\")\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.makedirs(DEST_TEXT_PATH, exist_ok=True)\n",
    "os.makedirs(DEST_AUDIO_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Starting parallel processing with {NUM_WORKERS} workers\")\n",
    "\n",
    "# Create progress bar for overall processing\n",
    "with tqdm(total=len(grouped_data), desc=\"Processing clients\") as pbar:\n",
    "    all_chars = set()\n",
    "    total_processed = 0\n",
    "    total_failed = 0\n",
    "    \n",
    "    # Process clients in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        # Submit all client processing tasks\n",
    "        future_to_client = {\n",
    "            executor.submit(process_client_data, (client_id, data)): client_id \n",
    "            for client_id, data in grouped_data.items()\n",
    "        }\n",
    "        \n",
    "        # Process completed tasks\n",
    "        for future in concurrent.futures.as_completed(future_to_client):\n",
    "            client_id = future_to_client[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                all_chars.update(result['chars'])\n",
    "                total_processed += result['processed']\n",
    "                total_failed += result['failed']\n",
    "            except Exception as e:\n",
    "                print(f\"Client {client_id} generated an exception: {str(e)}\")\n",
    "                total_failed += len(grouped_data[client_id])\n",
    "            pbar.update(1)\n",
    "\n",
    "print(\"\\nConversion Summary:\")\n",
    "print(f\"Total files processed successfully: {total_processed}\")\n",
    "print(f\"Total files failed: {total_failed}\")\n",
    "print(f\"Total unique characters: {len(all_chars)}\")\n",
    "print(\"Restructuring and conversion complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample, trim, normalize audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create destination directory if it doesn't exist\n",
    "os.makedirs(\"../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed\", exist_ok=True)\n",
    "\n",
    "# Copy all files from wav32 to wav16_silence_trimmed\n",
    "src_dir = \"../data/converted/commonvoice-to-gigaspeech/wav32\"\n",
    "dst_dir = \"../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed\"\n",
    "\n",
    "recursive_copy(src_dir, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling the audio files...\n",
      "Found 92956 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92956/92956 [01:32<00:00, 1000.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "# Resample all files in wav16_silence_trimmed to 16kHz\n",
    "SAMPLE_RATE = 16000\n",
    "NUM_RESAMPLE_THREADS = 4\n",
    "\n",
    "resample_audios(\n",
    "  input_folders=\"../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed\",\n",
    "  file_ext=\"wav\",\n",
    "  sample_rate=SAMPLE_RATE,\n",
    "  n_jobs=NUM_RESAMPLE_THREADS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /home/titor/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92956 .wav files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   1%|▏         | 1391/92956 [01:38<1:45:32, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv114/cv114_105_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   3%|▎         | 3223/92956 [04:03<2:03:27, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv123/cv123_251_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   7%|▋         | 6760/92956 [08:17<1:27:05, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv126/cv126_853_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   8%|▊         | 7588/92956 [09:17<1:30:21, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv063/cv063_111_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  10%|█         | 9651/92956 [11:36<1:31:25, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv032/cv032_010_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  11%|█         | 10321/92956 [12:26<1:22:30, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv031/cv031_067_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  26%|██▌       | 23959/92956 [29:02<1:38:21, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv125/cv125_946_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  32%|███▏      | 29742/92956 [36:30<1:11:04, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv133/cv133_202_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  42%|████▏     | 38817/92956 [47:59<1:13:00, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv046/cv046_030_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  44%|████▎     | 40453/92956 [50:00<1:00:11, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv039/cv039_039_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  45%|████▌     | 41891/92956 [51:43<59:28, 14.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv129/cv129_1648_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  45%|████▌     | 42245/92956 [52:08<56:51, 14.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv129/cv129_1729_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  49%|████▉     | 45662/92956 [56:40<56:33, 13.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv134/cv134_18451_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  56%|█████▌    | 51801/92956 [1:04:48<54:58, 12.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv134/cv134_13435_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  59%|█████▉    | 54980/92956 [1:08:58<39:38, 15.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv134/cv134_18844_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  70%|██████▉   | 64763/92956 [1:21:53<32:03, 14.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv134/cv134_15607_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  74%|███████▍  | 68834/92956 [1:27:15<28:40, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv134/cv134_8662_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  74%|███████▍  | 69006/92956 [1:27:29<33:27, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv134/cv134_10987_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  78%|███████▊  | 72587/92956 [1:31:31<22:07, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv131/cv131_2196_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  80%|████████  | 74380/92956 [1:33:31<18:26, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv132/cv132_4025_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  82%|████████▏ | 76074/92956 [1:35:08<14:28, 19.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv132/cv132_116_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  82%|████████▏ | 76142/92956 [1:35:12<14:47, 18.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv132/cv132_5889_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  82%|████████▏ | 76220/92956 [1:35:17<17:24, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv132/cv132_923_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  84%|████████▍ | 77998/92956 [1:36:58<12:52, 19.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv132/cv132_4774_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  95%|█████████▍| 88073/92956 [1:49:27<06:56, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv101/cv101_116_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  98%|█████████▊| 90995/92956 [1:53:08<02:01, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv107/cv107_384_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  98%|█████████▊| 91285/92956 [1:53:30<02:02, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv107/cv107_451_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  99%|█████████▉| 92001/92956 [1:54:18<01:09, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv013/cv013_103_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|█████████▉| 92682/92956 [1:55:06<00:19, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The file ../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv050/cv050_088_mic1.wav probably does not have speech please check it !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 92956/92956 [1:55:29<00:00, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete\n",
      "\n",
      "Found 29 files with no speech. List saved to ../data/converted/commonvoice-to-gigaspeech/no_speech_files.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trim_silence_with_vad(\n",
    "  input_folder=\"../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed\",\n",
    "  file_extension=\"wav\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Adjusting will lead to clipping of 2.772131000000001 dB\u001b[0m\n",
      "\u001b[33mWARNING: Adjusting will lead to clipping of 1.5261329999999993 dB\u001b[0m\n",
      "\u001b[33mWARNING: Adjusting will lead to clipping of 0.3622299999999983 dB\u001b[0m\n",
      "\u001b[33mWARNING: Adjusting will lead to clipping of 0.7675660000000017 dB\u001b[0m\n",
      "\u001b[33mWARNING: Adjusting will lead to clipping of 0.7587369999999982 dB\u001b[0m\n",
      "\u001b[33mWARNING: Adjusting will lead to clipping of 0.22026400000000024 dB\u001b[0m\n",
      "\u001b[33mWARNING: Adjusting will lead to clipping of 0.5259999999999962 dB\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Normalize the volume of all audio files to -27dB\n",
    "!find \"../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed\" -type f -name \"*.wav\" -exec sh -c 'ffmpeg-normalize \"$1\" -nt rms -t=-27 -o \"$1\" -ar 16000 -f' _ {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:00<00:00, 779.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total file pairs: 92956\n",
      "[('../data/converted/commonvoice-to-gigaspeech/txt/cv119/cv119_514.txt', '../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv119/cv119_514_mic1.wav', 'cv119_514'), ('../data/converted/commonvoice-to-gigaspeech/txt/cv119/cv119_364.txt', '../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv119/cv119_364_mic1.wav', 'cv119_364'), ('../data/converted/commonvoice-to-gigaspeech/txt/cv119/cv119_465.txt', '../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv119/cv119_465_mic1.wav', 'cv119_465'), ('../data/converted/commonvoice-to-gigaspeech/txt/cv119/cv119_856.txt', '../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv119/cv119_856_mic1.wav', 'cv119_856'), ('../data/converted/commonvoice-to-gigaspeech/txt/cv119/cv119_147.txt', '../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv119/cv119_147_mic1.wav', 'cv119_147')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_PATH = \"../data/converted/commonvoice-to-gigaspeech/txt\"\n",
    "AUDIO_PATH = \"../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed\"\n",
    "\n",
    "file_pairs = []\n",
    "for speaker in tqdm(os.listdir(SENTENCE_PATH)):\n",
    "    speaker_sentence_path = os.path.join(SENTENCE_PATH, speaker)\n",
    "    speaker_audio_path = os.path.join(AUDIO_PATH, speaker)\n",
    "    for file in os.listdir(speaker_sentence_path):\n",
    "        file_name = file.split('.')[0]\n",
    "        sentence_file = os.path.join(speaker_sentence_path, file)\n",
    "        audio_file = os.path.join(speaker_audio_path, file_name + '_mic1.wav')\n",
    "        file_pairs.append((sentence_file, audio_file, file.split('.')[0]))\n",
    "\n",
    "print(f\"Total file pairs: {len(file_pairs)}\")\n",
    "print(file_pairs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Val-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pairs: 74364\n",
      "Val pairs: 9296\n",
      "Test pairs: 9296\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(file_pairs)\n",
    "\n",
    "train_ratio, val_ratio, test_ratio = 0.8, 0.1, 0.1\n",
    "train_pairs = file_pairs[:int(len(file_pairs) * train_ratio)]\n",
    "val_pairs = file_pairs[int(len(file_pairs) * train_ratio): int(len(file_pairs) * (train_ratio + val_ratio))]\n",
    "test_pairs = file_pairs[int(len(file_pairs) * (train_ratio + val_ratio)):]\n",
    "\n",
    "print(f\"Train pairs: {len(train_pairs)}\")\n",
    "print(f\"Val pairs: {len(val_pairs)}\")\n",
    "print(f\"Test pairs: {len(test_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepairs):\n",
    "    features = ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path']\n",
    "    data = {f: [] for f in features}\n",
    "\n",
    "    for txt_file, wav_file, file_name in tqdm(filepairs):\n",
    "        \n",
    "        segment_id = file_name\n",
    "        speaker = file_name.split('_')[0]\n",
    "\n",
    "        with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "            text = f.readline().strip()\n",
    "        with open(wav_file, 'rb') as f: \n",
    "            audio_bytes = f.read()\n",
    "            \n",
    "        file_like_object = io.BytesIO(audio_bytes)\n",
    "        audio_array, sr = sf.read(file_like_object)\n",
    "\n",
    "        begin_time = 0.0\n",
    "        end_time = audio_array.shape[0] / sr\n",
    "        audio_id = file_name\n",
    "        title = file_name\n",
    "        url = 'N/A'\n",
    "        source = 'cv-corpus-20.0-2024-12-06'\n",
    "        category = 10\n",
    "        original_full_path = ''\n",
    "\n",
    "        data['segment_id'].append(segment_id)\n",
    "        data['speaker'].append(speaker)\n",
    "        data['text'].append(text)\n",
    "        data['audio'].append(wav_file)\n",
    "        data['begin_time'].append(begin_time)\n",
    "        data['end_time'].append(end_time)\n",
    "        data['audio_id'].append(audio_id)\n",
    "        data['title'].append(title)\n",
    "        data['url'].append(url)\n",
    "        data['source'].append(source)\n",
    "        data['category'].append(category)\n",
    "        data['original_full_path'].append(original_full_path)\n",
    "\n",
    "    return Dataset.from_dict(data).cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74364/74364 [00:24<00:00, 2998.68it/s]\n",
      "100%|██████████| 9296/9296 [00:03<00:00, 3005.24it/s]\n",
      "100%|██████████| 9296/9296 [00:03<00:00, 3087.88it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data(train_pairs)\n",
    "val_data = load_data(val_pairs)\n",
    "test_data = load_data(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segment_id': 'cv014_004', 'speaker': 'cv014', 'text': 'การฆาตกรรมเป็นการกระทำที่หยาบช้า', 'audio': {'path': '../data/converted/commonvoice-to-gigaspeech/wav16_silence_trimmed/cv014/cv014_004_mic1.wav', 'array': array([-0.00076294, -0.0005188 , -0.00039673, ...,  0.01580811,\n",
      "        0.01452637,  0.01071167]), 'sampling_rate': 16000}, 'begin_time': 0.0, 'end_time': 2.428, 'audio_id': 'cv014_004', 'title': 'cv014_004', 'url': 'N/A', 'source': 'cv-corpus-20.0-2024-12-06', 'category': 10, 'original_full_path': ''}\n"
     ]
    }
   ],
   "source": [
    "print(val_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n",
      "        num_rows: 74364\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n",
      "        num_rows: 9296\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['segment_id', 'speaker', 'text', 'audio', 'begin_time', 'end_time', 'audio_id', 'title', 'url', 'source', 'category', 'original_full_path'],\n",
      "        num_rows: 9296\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = DatasetDict({'train': train_data, 'validation': val_data, 'test': test_data})\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push to Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab42d9b0bc2a440f909ae9ad9d8e6fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e093d15d584441138aca5e92458cb9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5721 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f110d5a3e742d7b703c207fdb52f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ae4c020f8146adae4e349638047629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5721 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136b8089721241569c11dea69ef78663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b252f5ffd8384cd684d1205b5037de1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5721 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5bfa5f20d94c5ca18f456316bc38ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0e13fb99cc42188f1654f5eb057d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5721 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2be2b4a04884317a7dbf4991b5be017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025252b3171e46bd93fd0003e2c391f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7eaa43549f44e78a414183ddf8850ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99714af52aa4e1e8dba1825ba4d714d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04330b68cd7147adac9ed15012e12764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a2dd7f405f41fcb84100896943f91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0c7c27b8174bd4adababd37dce8b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bf17f8d6e1417a8b54cf537210d195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3d598c54f149c1ac9943fda0c17201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f258ccd6c048918c0d1aae4235d93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcb5ee4a05e46c89688498cc6fc66e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d087575d99bc459683c2a17b8e5fa9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00c3bb909614c72a22a2e4ee3c0ed22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de81f3a0b59044ca98bf08c4d0b8134b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b23e8c18ab4bc8bc726bcd46f28a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa68eeb05d34ebe903f2d56274d0224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4106329e8e2e40149b8bc3f2c401e246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759210fc12194eac9dd89619e13e76bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f2a3c911c5408ca4f2027d974d1009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f402dd62e00041f88694d086c2419a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2859ad39fbd4337a8b0d185ea90103c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5b140fe5ba4bec8db7fdf962188095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/47 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac62ac047344450880072e3165dec71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5602305fe85e4e3087bef86449234b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/47 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128d9ffa73454f2eaf2b908a75b0545d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27b8739849e4ddfb9eae88801669f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1411a029a7b94145982a534fc5e8b02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/47 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2210706d1fc4c8788613f12baf10cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1165e62be0cc4bad845769fe24a4fc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/47 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/dubbing-ai/commonvoice-to-gigaspeech/commit/2bd2c5e77744c769cdf9be5a9fb441016ec40fe6', commit_message='Upload dataset', commit_description='', oid='2bd2c5e77744c769cdf9be5a9fb441016ec40fe6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/dubbing-ai/commonvoice-to-gigaspeech', endpoint='https://huggingface.co', repo_type='dataset', repo_id='dubbing-ai/commonvoice-to-gigaspeech'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict.push_to_hub('dubbing-ai/commonvoice-to-gigaspeech')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-dataset-converter-n9RbnRje-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
